# check.packages function: install and load multiple R packages.
# Check to see if packages are installed. Install them if they are not, then load them into the R session.
check.packages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}



  compute_struct_vector<-function (golden_bn, bn_learnt, score_measured) {
    struct.list=list()
    compte=compare(golden_bn,bn_learnt)
    compte=c(compte,tn=nnodes(gloden_bn)*(nnodes(golden_bn)-1)-compte$tp-compte$fp-compte$fn)
    compte=c(compte,recall=compte$tp/(compte$tp+compte$fn), precision=compte$tp/(compte$tp+compte$fp),compte$tn/(compte$tn+compte$fp))
    compte=c(compte,fscore=2*(scores_results$recall*scores_results$precision)/(scores_results$recall+scores_results$precision))
    compte=c(compte,sqrt((1-compte$precision)^2+ (1-compte$precision)^2))
    
    for (struct_score in score_measured) {
      individual_score=switch(struct_score,
             "shd" = shd(golden_bn,bn_learnt),
             "hamming" = hamming(golden_bn,bn_learnt),
             "tp" = compte$tp,
             "fp" = compte$fp,
             "fn" = compte$fn,
             "tn" = compte$tn,
             "recall" = compte$recall,
             "precision"=compte$precision,
             "specificity"=compte$specificity,
             "fscore"=compte$fscore,
             "dist2opt"=compte$dist2opt,
      )
      struct.list=c(struct.list, struct_score=individual_score) 
    }
    return (struct.list)
  }
  
  
  
  
  compute_proba_vector<- function (bn_learnt, data.set, score_measured,type="train") {
    
      proba.list=list()
      for (proba_score in score_measured) {
        
        individual_score=switch(strsplit(proba_score,split="_")[[1]][1],
                                "bic" = score(bn_learnt,data.set,"bic"),
                                "aic"= score(bn_learnt,data.set,"aic"),
                                "loglik" = score(bn_learnt,data.set,"loglik"),
                                "bde" = score(bn_learnt,data.set,"bde")
        )
        
        proba.list=c(proba.list, proba_score=individual_score) 
      }
      return (proba.list)
  }
  
  compute_structural_scores<- function(golden_bn, size,restrict,score_measured, restrict.args) {
    
    temp_database=rbn(golden_bn, n = size)
    start.time <- Sys.time()
    bn_learnt=rsmax2(temp_database, restrict = restrict, maximize = "tabu", restrict.args = restrict.args, maximize.args = list(tabu = 100, max.tabu = 20) )
    end.time <- Sys.time()
    time.taken <- as.numeric(end.time - start.time)
    structural_result=compute_struct_vector(golden_bn,bn_learnt,score_measured)
    if ("time" %in% score_measured) {
      structural_result=c(structural_result,time=time.taken)
    }
    return (structural_result)
  }
    
  
  compute_probalistic_scores<- function(golden_bn, size,restrict,score_measured, restrict.args,n_splits=10){
    
    
    flds <- createFolds(seq(1,size,1), k = n_splits, list = TRUE, returnTrain = FALSE)
    df_proba <- data.frame(matrix(ncol = length(score_measured), nrow = 0))
    colnames(df_proba) <- score_measured
  
    for (index_fold in seq_along(flds)) {
      train_data=data_random[-flds[[index_fold]],]
      print("les donnes apprisses sont ")
      print(train_data)
      bn_learnt=rsmax2(train_data, restrict = restrict, maximize = "tabu", restrict.args = restrict.args, maximize.args = list(tabu = 100, max.tabu = 20) )
      test_data=data_random[flds[[index_fold]],]
      train_score=data.frame(compute_proba_vector(bn_learnt,train_data,score_measured))
      test_score=data.frame(compute_proba_vector(bn_learnt,test_data,score_measured))
      fused_score=cbind(train_score,test_score)
      df_proba=rbind(df_proba,fused_score)
    }
    return (colMeans(df_proba))
  }
    
  
  compute_average_distance<- function(golden_bn, nsamples,size,algorithm,proba_score,struct_score,n_splits,restrict.args) {
    #matrix of shape (repetitions * scores) to get the mean of each type of score
    #algorithm:(type,agrs,kwargs)
    
    column_names=c(proba_score,struct_score)
    scoring_df=data.frame(matrix(nrow = 0, ncol = length(column_names)))
    colnames(scoring_df) <- column_names
    
    for (repetition in seq(1,nsamples,1)) {
      if (length(proba_score>0)) {
        temp_proba=compute_probalistic_scores(golden_bn, size,algorithm,proba_score, restrict.args=restrict.args,n_splits=n_splits)
        
      }
      
      if (length(struct_score>0)) {
        temp_struct=compute_structural_scores(golden_bn, size,algorithm,struct_score, restrict.args=restrict.argsb)
      }
      temp_score=cbind(temp_proba,temp_struct)
      scoring_df=rbind(scoring_df,temp_score)
    } 
      return (scoring_df)
  }
   
  
  learn_scores<- function(name_bn,sample_size,score_measured=c('dist2opt'),algorithms=c('hpc'),n_splits=10,nsamples=30,restrict.args=list()) {
     
    proba_scores=c('recall','precision','fscore','dist2opt','specificity','hamming','shd','time','number_tests')
    structural_scores=c('bic_train','aic_train','loglik_train',"bde_train",'aic_test','loglik_test','bic_test','bde_test')
    
    bn=read.bif(file.path("true_graphes_structures",name_bn))
    struct.vector=c()
    proba.vector=c()
    for (score in score_measured) {
      if (!(score %in% c(structural_scores,proba_scores))) {
        stop(cat("distance score still not implemented, list of of possible computations is ",c(structural_scores,proba_scores)))
      }
      if (score %in% structural_scores)   struct.vector=c(struct.vector,score)
      if (score %in% proba_scores)      proba.vector=c(proba.vector,score)
    }
    struct.vector=sort(struct.vector)
    proba.vector=sort(proba.vector)
    
    restrain_algorithms=c('si.hiton.pc','hpc', 'mmpc', 'iamb.fdr', 'gs','pc.stable')
    #assert that algorithms are computed
    for (algo in algorithms) {
      if (! (algo %in% restrain_algorithms)) {
        stop("algorithm still not implemented")
      }
    } 
     
    
    #matrix scoring all scores measured for each database
    df_score_final=data.frame(matrix(nrow = 0, ncol = length(score_measured)))
    colnames(df_score_final) <- c(struct.vector,proba.vector)
    for (size in sample_size) {
      cat("\n We are at size ", size,"\n")
      for (algorithm in algorithms) {
        cat("nous en sommes a l'algo ", algorithm, "pour la taille suivante de database ", size,"\n")
        df_score_final=rbind(df_score_final, compute_average_distance(bn, nsamples,size,algorithm,proba_score=proba.vector,struct_score=struct.vector,n_splits=n_splits,restrict.args=restrict.args))
      }
    }
    write.csv(df_score_final, file=file.path('scores',paste0('scores_total_{}', sub("^([^.]*).*", "\\1", name_bn) )))
    return (df_score_final)
  }    
  
  
  #install packages
  packages<-c("caret","parallel","snow")
  check.packages(packages)
  
  liste_graphes=list.files(path = "true_graphes_structures")
  score_measured=c('recall','precision','dist2opt','specificity','hamming','shd','bic_train','aic_train','aic_test','bic_test')
  algorithms=c('hpc')
  sample_size=c(500,1000,2000,5000,10000,20000,50000)
  for (graph in liste_graphes) {
    cat("we learn following graph ", graph)
    learn_scores(graph,sample_size,score_measured=score_measured,algorithms=algorithms,n_splits=10,nsamples=30,restrict.args=list(test="x2",debug=TRUE))
  }
  

  
  
  
  
  
  